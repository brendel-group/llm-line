{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import itertools\n",
    "import scipy.stats as stats\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cwd\n",
    "os.chdir('/lustre/fast/fast/pmayilvahanan/llm_line/code/llm_line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_scatter(csv_file, dataset1, dataset2, step_interval=1000, pretraining_data=None, min_step=0):\n",
    "    \"\"\"\n",
    "    Create a scatter plot comparing performance on two datasets\n",
    "    \n",
    "    Args:\n",
    "        csv_file: path to the CSV file containing the results\n",
    "        dataset1: name of first dataset (x-axis)\n",
    "        dataset2: name of second dataset (y-axis)\n",
    "        step_interval: plot points at every step_interval steps (default: 1000)\n",
    "        pretraining_data: list of specific pretraining datasets to include (default: None, includes all)\n",
    "        min_step: minimum step to start plotting from (default: 0)\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Filter steps based on interval and minimum step\n",
    "    df = df[(df['steps'] % step_interval == 0) & (df['steps'] >= min_step)]\n",
    "    \n",
    "    # Filter by specific pretraining datasets if provided\n",
    "    if pretraining_data is not None:\n",
    "        df = df[df['runname'].isin(pretraining_data)]\n",
    "    \n",
    "    # Construct column names\n",
    "    x_col = f\"{dataset1}/acc\"\n",
    "    y_col = f\"{dataset2}/acc\"\n",
    "    \n",
    "    # Check if columns exist\n",
    "    if x_col not in df.columns or y_col not in df.columns:\n",
    "        raise ValueError(f\"Columns {x_col} or {y_col} not found in the data.\")\n",
    "    \n",
    "    # Create figure and axis\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Create scatter plot\n",
    "    sns.scatterplot(data=df, x=x_col, y=y_col, hue='runname', alpha=0.6)\n",
    "    \n",
    "    # Dictionary to store R² values\n",
    "    r2_values = {}\n",
    "    \n",
    "    # Add trend line for each runname and calculate R²\n",
    "    for name in df['runname'].unique():\n",
    "        subset = df[df['runname'] == name]\n",
    "        \n",
    "        # Calculate regression line\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "            subset[x_col], subset[y_col]\n",
    "        )\n",
    "        r2 = r_value ** 2\n",
    "        r2_values[name] = r2\n",
    "        \n",
    "        # Plot regression line\n",
    "        sns.regplot(data=subset, x=x_col, y=y_col, \n",
    "                   scatter=False, \n",
    "                   label=f\"{name} (R² = {r2:.3f})\", \n",
    "                   ci=None)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(f'Model Performance: {dataset1} vs {dataset2}\\n(Steps interval: {step_interval}, Min step: {min_step})')\n",
    "    plt.xlabel(f'{dataset1} Accuracy')\n",
    "    plt.ylabel(f'{dataset2} Accuracy')\n",
    "    \n",
    "    # Adjust legend\n",
    "    plt.legend(title='Pretraining Data', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Print detailed fit statistics\n",
    "    print(\"\\nDetailed Fit Statistics:\")\n",
    "    print(\"-\" * 50)\n",
    "    for name in r2_values:\n",
    "        subset = df[df['runname'] == name]\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "            subset[x_col], subset[y_col]\n",
    "        )\n",
    "        print(f\"\\nPretraining Data: {name}\")\n",
    "        print(f\"R² Score: {r2_values[name]:.3f}\")\n",
    "        print(f\"Slope: {slope:.3f}\")\n",
    "        print(f\"Intercept: {intercept:.3f}\")\n",
    "        print(f\"P-value: {p_value:.3e}\")\n",
    "        print(f\"Standard Error: {std_err:.3e}\")\n",
    "    \n",
    "    # Adjust layout to prevent legend cutoff\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "create_performance_scatter(\n",
    "    'finweb_results.csv', \n",
    "    'hellaswag', \n",
    "    'mmlu', \n",
    "    step_interval=1000, \n",
    "    pretraining_data=['C4', 'The Pile', 'RefineWeb', 'RedPajama2'],\n",
    "    min_step=50000\n",
    ")\n",
    "#create_performance_scatter('finweb_results.csv', 'arc', 'piqa', step_interval=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_scatterplot_grid(csv_file, datasets, step_interval=1000, pretraining_data=None, min_step=0):\n",
    "#     \"\"\"\n",
    "#     Create a grid of scatter plots for each pair of downstream tasks.\n",
    "    \n",
    "#     Args:\n",
    "#         csv_file: path to the CSV file containing the results\n",
    "#         datasets: list of dataset names to compare\n",
    "#         step_interval: plot points at every step_interval steps (default: 1000)\n",
    "#         pretraining_data: list of specific pretraining datasets to include (default: None, includes all)\n",
    "#         min_step: minimum step to start plotting from (default: 0)\n",
    "#     \"\"\"\n",
    "#     num_datasets = len(datasets)\n",
    "#     fig, axes = plt.subplots(num_datasets, num_datasets, figsize=(15, 15))\n",
    "    \n",
    "#     for i, j in itertools.combinations(range(num_datasets), 2):\n",
    "#         dataset1 = datasets[i]\n",
    "#         dataset2 = datasets[j]\n",
    "        \n",
    "#         ax = axes[i, j]\n",
    "#         plt.sca(ax)  # Set current axis\n",
    "        \n",
    "#         # Create scatter plot for the current pair of datasets\n",
    "#         create_performance_scatter(csv_file, dataset1, dataset2, step_interval, pretraining_data, min_step)\n",
    "        \n",
    "#         # Remove axis labels for cleaner grid\n",
    "#         ax.set_xlabel('')\n",
    "#         ax.set_ylabel('')\n",
    "    \n",
    "#     # Remove unused subplots (diagonal and lower triangle)\n",
    "#     for i in range(num_datasets):\n",
    "#         for j in range(num_datasets):\n",
    "#             if i >= j:\n",
    "#                 fig.delaxes(axes[i, j])\n",
    "    \n",
    "#     # Adjust layout\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Example usage\n",
    "# datasets = ['hellaswag', 'commonsense_qa', 'arc', 'piqa']\n",
    "# create_scatterplot_grid(\n",
    "#     'finweb_results.csv', \n",
    "#     datasets, \n",
    "#     step_interval=10000, \n",
    "#     pretraining_data=['C4', 'The Pile', 'RefineWeb', 'RedPajama2'],\n",
    "#     min_step=50000\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import itertools\n",
    "\n",
    "def create_performance_scatter(csv_file, dataset1, dataset2, step_interval=1000, pretraining_data=None, min_step=0, ax=None):\n",
    "    \"\"\"\n",
    "    Create a scatter plot comparing performance on two datasets\n",
    "    \n",
    "    Args:\n",
    "        csv_file: path to the CSV file containing the results\n",
    "        dataset1: name of first dataset (x-axis)\n",
    "        dataset2: name of second dataset (y-axis)\n",
    "        step_interval: plot points at every step_interval steps (default: 1000)\n",
    "        pretraining_data: list of specific pretraining datasets to include (default: None, includes all)\n",
    "        min_step: minimum step to start plotting from (default: 0)\n",
    "        ax: matplotlib axis to plot on (default: None, creates new figure)\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Filter steps based on interval and minimum step\n",
    "    df = df[(df['steps'] % step_interval == 0) & (df['steps'] >= min_step)]\n",
    "    \n",
    "    # Filter by specific pretraining datasets if provided\n",
    "    if pretraining_data is not None:\n",
    "        df = df[df['runname'].isin(pretraining_data)]\n",
    "    \n",
    "    # Construct column names\n",
    "    x_col = f\"{dataset1}/acc\"\n",
    "    y_col = f\"{dataset2}/acc\"\n",
    "    \n",
    "    # Check if columns exist\n",
    "    if x_col not in df.columns or y_col not in df.columns:\n",
    "        raise ValueError(f\"Columns {x_col} or {y_col} not found in the data.\")\n",
    "    \n",
    "    # Create new figure if no axis provided\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    # Create scatter plot\n",
    "    sns.scatterplot(data=df, x=x_col, y=y_col, hue='runname', alpha=0.6, ax=ax)\n",
    "    \n",
    "    # Dictionary to store R² values\n",
    "    r2_values = {}\n",
    "    \n",
    "    # Add trend line for each runname and calculate R²\n",
    "    for name in df['runname'].unique():\n",
    "        subset = df[df['runname'] == name]\n",
    "        \n",
    "        # Calculate regression line\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "            subset[x_col], subset[y_col]\n",
    "        )\n",
    "        r2 = r_value ** 2\n",
    "        r2_values[name] = r2\n",
    "        \n",
    "        # Plot regression line\n",
    "        sns.regplot(data=subset, x=x_col, y=y_col, \n",
    "                   scatter=False, \n",
    "                   label=f\"{name} (R² = {r2:.3f})\", \n",
    "                   ci=None,\n",
    "                   ax=ax)\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_title(f'{dataset1} vs {dataset2}\\n(Steps: {step_interval}, Min: {min_step})')\n",
    "    ax.set_xlabel(f'{dataset1} Accuracy')\n",
    "    ax.set_ylabel(f'{dataset2} Accuracy')\n",
    "    \n",
    "    # Return the axis and fit statistics\n",
    "    return ax, r2_values\n",
    "\n",
    "def create_scatterplot_grid(csv_file, datasets, step_interval=1000, pretraining_data=None, min_step=0):\n",
    "    \"\"\"\n",
    "    Create a grid of scatter plots for each pair of downstream tasks.\n",
    "    \n",
    "    Args:\n",
    "        csv_file: path to the CSV file containing the results\n",
    "        datasets: list of dataset names to compare\n",
    "        step_interval: plot points at every step_interval steps (default: 1000)\n",
    "        pretraining_data: list of specific pretraining datasets to include (default: None, includes all)\n",
    "        min_step: minimum step to start plotting from (default: 0)\n",
    "    \"\"\"\n",
    "    num_datasets = len(datasets)\n",
    "    fig, axes = plt.subplots(num_datasets, num_datasets, figsize=(30, 30))\n",
    "    \n",
    "    # Store all R² values\n",
    "    all_stats = {}\n",
    "    \n",
    "    for i, j in itertools.combinations(range(num_datasets), 2):\n",
    "        dataset1 = datasets[i]\n",
    "        dataset2 = datasets[j]\n",
    "        \n",
    "        # Create scatter plot for the current pair of datasets\n",
    "        ax, r2_values = create_performance_scatter(\n",
    "            csv_file, dataset1, dataset2, \n",
    "            step_interval, pretraining_data, min_step,\n",
    "            ax=axes[i, j]\n",
    "        )\n",
    "        \n",
    "        # Store statistics\n",
    "        all_stats[(dataset1, dataset2)] = r2_values\n",
    "        \n",
    "        # Remove legend for cleaner grid (except for rightmost plots)\n",
    "        if j != num_datasets-1:\n",
    "            ax.get_legend().remove()\n",
    "    \n",
    "    # Remove unused subplots (diagonal and lower triangle)\n",
    "    for i in range(num_datasets):\n",
    "        for j in range(num_datasets):\n",
    "            if i >= j:\n",
    "                fig.delaxes(axes[i, j])\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Print all fit statistics\n",
    "    print(\"\\nDetailed Fit Statistics:\")\n",
    "    print(\"-\" * 50)\n",
    "    for (dataset1, dataset2), r2_values in all_stats.items():\n",
    "        print(f\"\\nComparison: {dataset1} vs {dataset2}\")\n",
    "        for name, r2 in r2_values.items():\n",
    "            print(f\"{name}: R² = {r2:.3f}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "datasets = ['hellaswag', 'commonsense_qa', 'arc', 'piqa', 'sciq', 'mmlu']\n",
    "create_scatterplot_grid(\n",
    "    'finweb_results.csv', \n",
    "    datasets, \n",
    "    step_interval=10000, \n",
    "    pretraining_data=['C4', 'The Pile', 'RefineWeb', 'RedPajama2'],\n",
    "    min_step=50000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import itertools\n",
    "\n",
    "def create_performance_scatter(csv_file, dataset1, dataset2, step_interval=1000, pretraining_data=None, min_step=0, ax=None):\n",
    "    \"\"\"\n",
    "    Create a scatter plot comparing performance on two datasets\n",
    "    \n",
    "    Args:\n",
    "        csv_file: path to the CSV file containing the results\n",
    "        dataset1: name of first dataset (x-axis)\n",
    "        dataset2: name of second dataset (y-axis)\n",
    "        step_interval: plot points at every step_interval steps (default: 1000)\n",
    "        pretraining_data: list of specific pretraining datasets to include (default: None, includes all)\n",
    "        min_step: minimum step to start plotting from (default: 0)\n",
    "        ax: matplotlib axis to plot on (default: None, creates new figure)\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Filter steps based on interval and minimum step\n",
    "    df = df[(df['steps'] % step_interval == 0) & (df['steps'] >= min_step)]\n",
    "    \n",
    "    # Filter by specific pretraining datasets if provided\n",
    "    if pretraining_data is not None:\n",
    "        df = df[df['runname'].isin(pretraining_data)]\n",
    "    \n",
    "    # Construct column names\n",
    "    x_col = f\"{dataset1}/acc\"\n",
    "    y_col = f\"{dataset2}/acc\"\n",
    "    \n",
    "    # Check if columns exist\n",
    "    if x_col not in df.columns or y_col not in df.columns:\n",
    "        raise ValueError(f\"Columns {x_col} or {y_col} not found in the data.\")\n",
    "    \n",
    "    # Create new figure if no axis provided\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    # Create scatter plot\n",
    "    scatter = sns.scatterplot(data=df, x=x_col, y=y_col, hue='runname', alpha=0.6, ax=ax)\n",
    "    \n",
    "    # Remove the scatter plot legend if it exists\n",
    "    legend = scatter.get_legend()\n",
    "    if legend:\n",
    "        legend.remove()\n",
    "    \n",
    "    # Dictionary to store R² values\n",
    "    r2_values = {}\n",
    "    \n",
    "    # Add trend line for each runname and calculate R²\n",
    "    for name in df['runname'].unique():\n",
    "        subset = df[df['runname'] == name]\n",
    "        \n",
    "        # Calculate regression line\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "            subset[x_col], subset[y_col]\n",
    "        )\n",
    "        r2 = r_value ** 2\n",
    "        r2_values[name] = r2\n",
    "        \n",
    "        # Plot regression line with R² in the legend\n",
    "        sns.regplot(data=subset, x=x_col, y=y_col, \n",
    "                   scatter=False, \n",
    "                   label=f\"{name} (R²={r2:.2f})\", \n",
    "                   ci=None,\n",
    "                   ax=ax)\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_title(f'{dataset1} vs {dataset2}\\n(Steps: {step_interval}, Min: {min_step})')\n",
    "    ax.set_xlabel(f'{dataset1} Accuracy')\n",
    "    ax.set_ylabel(f'{dataset2} Accuracy')\n",
    "    \n",
    "    # Return the axis and fit statistics\n",
    "    return ax, r2_values\n",
    "\n",
    "def create_scatterplot_grid(csv_file, datasets, step_interval=1000, pretraining_data=None, min_step=0):\n",
    "    \"\"\"\n",
    "    Create a grid of scatter plots for each pair of downstream tasks.\n",
    "    \n",
    "    Args:\n",
    "        csv_file: path to the CSV file containing the results\n",
    "        datasets: list of dataset names to compare\n",
    "        step_interval: plot points at every step_interval steps (default: 1000)\n",
    "        pretraining_data: list of specific pretraining datasets to include (default: None, includes all)\n",
    "        min_step: minimum step to start plotting from (default: 0)\n",
    "    \"\"\"\n",
    "    num_datasets = len(datasets)\n",
    "    fig, axes = plt.subplots(num_datasets, num_datasets, figsize=(30, 30))\n",
    "    \n",
    "    for i, j in itertools.combinations(range(num_datasets), 2):\n",
    "        dataset1 = datasets[i]\n",
    "        dataset2 = datasets[j]\n",
    "        \n",
    "        # Create scatter plot for the current pair of datasets\n",
    "        ax, _ = create_performance_scatter(\n",
    "            csv_file, dataset1, dataset2, \n",
    "            step_interval, pretraining_data, min_step,\n",
    "            ax=axes[i, j]\n",
    "        )\n",
    "        \n",
    "        # Remove legend for cleaner grid (except for rightmost plots)\n",
    "        if j != num_datasets-1:\n",
    "            legend = ax.get_legend()\n",
    "            if legend:\n",
    "                legend.remove()\n",
    "    \n",
    "    # Remove unused subplots (diagonal and lower triangle)\n",
    "    for i in range(num_datasets):\n",
    "        for j in range(num_datasets):\n",
    "            if i >= j:\n",
    "                fig.delaxes(axes[i, j])\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "datasets = ['hellaswag', 'commonsense_qa', 'arc', 'piqa', 'sciq', 'mmlu']\n",
    "create_scatterplot_grid(\n",
    "    'finweb_results.csv', \n",
    "    datasets, \n",
    "    step_interval=10000, \n",
    "    pretraining_data=['C4', 'The Pile', 'RefineWeb', 'RedPajama2'],\n",
    "    min_step=50000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
