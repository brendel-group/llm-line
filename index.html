<!doctype html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Primary Meta Tags -->
    <title>LLMs on the Line: Data Determines Loss-To-Loss Scaling Laws</title>
    <meta name="title" content="LLMs on the Line: Data Determines Loss-To-Loss Scaling Laws">
    <meta name="description"
        content="Scaling laws guide the development of large language models (LLMs) by offering estimates for the optimal balance of model size, tokens, and compute. More recently, loss-to-loss scaling laws that relate losses across pretraining datasets and downstream tasks have emerged as a powerful tool for understanding and improving LLM performance. In this work, we investigate which factors most strongly influence loss-to-loss scaling. Our experiments reveal that the pretraining data and tokenizer determine the scaling trend. In contrast, model size, optimization hyperparameters, and even significant architectural differences, such as between transformer-based models like Llama and state-space models like Mamba, have limited impact. Consequently, practitioners should carefully curate suitable pretraining datasets for optimal downstream performance, while architectures and other settings can be freely optimized for training efficiency.">
    
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://brendel-group.github.io/llm-line">
    <meta property="og:title" content="LLMs on the Line: Data Determines Loss-To-Loss Scaling Laws">
    <meta property="og:description"
        content="Scaling laws guide the development of large language models (LLMs) by offering estimates for the optimal balance of model size, tokens, and compute. More recently, loss-to-loss scaling laws that relate losses across pretraining datasets and downstream tasks have emerged as a powerful tool for understanding and improving LLM performance. In this work, we investigate which factors most strongly influence loss-to-loss scaling. Our experiments reveal that the pretraining data and tokenizer determine the scaling trend. In contrast, model size, optimization hyperparameters, and even significant architectural differences, such as between transformer-based models like Llama and state-space models like Mamba, have limited impact. Consequently, practitioners should carefully curate suitable pretraining datasets for optimal downstream performance, while architectures and other settings can be freely optimized for training efficiency.">
    <meta property="og:image" content="https://brendel-group.github.io/llm-line/img/fig1.svg">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://brendel-group.github.io/llm-line">
    <meta property="twitter:title" content="LLMs on the Line: Data Determines Loss-To-Loss Scaling Laws">
    <meta property="twitter:description"
        content="Scaling laws guide the development of large language models (LLMs) by offering estimates for the optimal balance of model size, tokens, and compute. More recently, loss-to-loss scaling laws that relate losses across pretraining datasets and downstream tasks have emerged as a powerful tool for understanding and improving LLM performance. In this work, we investigate which factors most strongly influence loss-to-loss scaling. Our experiments reveal that the pretraining data and tokenizer determine the scaling trend. In contrast, model size, optimization hyperparameters, and even significant architectural differences, such as between transformer-based models like Llama and state-space models like Mamba, have limited impact. Consequently, practitioners should carefully curate suitable pretraining datasets for optimal downstream performance, while architectures and other settings can be freely optimized for training efficiency.">
    <meta property="twitter:image" content="https://brendel-group.github.io/llm-line/img/fig1.svg">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css"
        integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans+Condensed&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono&display=swap" rel="stylesheet">

    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.9.3/Chart.min.js"></script>

    <style>
        .main {
            font-family: 'IBM Plex Sans Condensed', sans-serif;
        }

        .code {
            font-family: 'IBM Plex Mono', monospace;
        }

        h3 {
            margin-top: 1.0rem; 
        }

        .row-dense {
            padding-bottom: 0;
        }

        .a {
            color: gainsboro;
            font-family: 'IBM Plex Sans Condensed', sans-serif;
        }

        td {
            padding: 0 15px;
        }

        p {
            text-align: justify;

        }

        .collapse-container {
            text-align: center;
            position: relative;

        }

        .collapse-container #moreless.collapsed:after {
            content: '+ Show More';
        }

        .collapse-container #moreless:not(.collapsed):after {
            content: '- Show Less';
        }

        .collapse-container .collapse.collapse:not(.show) {
            display: block;
            /* height = lineheight * no of lines to display */
            height: 7.7em;
            overflow: hidden;
        }

        .collapse-container .collapse.collapse:not(.show):before {
            content: '';
            width: 100%;
            height: 7.7em;
            position: absolute;
            left: 0;
            top: 0;
            background: linear-gradient(rgba(255, 255, 255, 0), 60px, white);
        }

        .collapse-container .collapse.collapsing {
            height: 7.7em;
        }
    </style>

    <title>LLMs on the Line: Data Determines Loss-To-Loss Scaling Laws</title>
</head>

<body>
    <div class="container main">
        <div class="row">
            <div class="col-sm-2">
            </div>
            <div class="col-sm-8" id="main-content">
                <div class="row text-center my-5" id="#">
                    <h1>LLMs on the Line: Data Determines Loss-To-Loss Scaling Laws</h1>
                </div>

                <!-- Begin author list-->
                <div class="row text-center mb-4">
                    <div class="col-sm-4 mb-4">
                        Prasanna Mayilvahanan*
                        <a href="mailto:attila.juhos@tuebingen.mpg.de"><i class="far fa-envelope"></i></a>
                        <a href="https://twitter.com/JuhosAttila"><i class="fab fa-x-twitter"></i></a><br>
                        MPI-IS, University of Tübingen, Tübingen AI Center
                    </div>
                    <div class="col-sm-4 mb-4">
                        Thaddäus Wiedemer*
                        <a href="mailto:thaddaeus.wiedemer@gmail.com"><i class="far fa-envelope"></i></a>
                        <a href="https://twitter.com/thwiedemer"><i class="fab fa-x-twitter"></i></a><br>
                        MPI-IS, University of Tübingen, Tübingen AI Center
                    </div>
                    <div class="col-sm-4 mb-4">
                        Sayak Mallick*
                        <a href="mailto:"><i class="far fa-envelope"></i></a>
                        <a href="https://twitter.com/kotekjedi_ml"><i class="fab fa-x-twitter"></i></a><br>
                        University of Tübingen, MPI-IS, TÜbingen AI Center
                    </div>
                    <div class="col-sm-4 mb-4">
                        Jack Brady*
                        <a href="mailto:jack.brady@tuebingen.mpg.de"><i class="far fa-envelope"></i></a>
                        <a href="https://twitter.com/jackhb98"><i class="fab fa-x-twitter"></i></a><br>
                        MPI-IS, University if Tübingen, Tübingen AI Center
                    </div>
                    <div class="col-sm-4 mb-4">
                        Matthias Bethge
                        <a href="mailto:matthias@bethgelab.org"><i class="far fa-envelope"></i></a><br>
                        University of Tübingen, Tübingen AI Center
                    </div>
                    <div class="col-sm-4 mb-4">
                        Wieland Brendel
                        <a href="mailto:wieland.brendel@tue.mpg.de"><i class="far fa-envelope"></i></a><br>
                        MPI-IS, ELLIS Institute Tübingen, Tübingen AI Center
                    </div>
                </div>
                <!-- End author list-->

                <div class="row text-center">
                    <div class="col-sm-4 mb-4 offset-sm-2">
                        <h4>
                            <a href="https://arxiv.org/abs/xxxxxxxx" target="_blank">
                                <i class="fas fa-file-alt"></i>
                                Paper
                            </a>
                        </h4>
                    </div>
                    <div class="col-sm-4 mb-4">
                        <h4>
                            <a href="https://github.com/brendel-group/llm-line" target="_blank">
                                <i class="fab fa-github"></i>
                                Code
                            </a>
                        </h4>
                    </div>
                </div>

                <div class="row text-center">
                    <p>
                        <b>tl;dr:</b>
                        <span class="text-muted">
                            We investigate which factors most strongly influence loss-to-loss scaling.
                        </span>
                    </p>
                </div>

                <div class="row mt-2">
                    <h3>News</h3>
                </div>

                <div class="row">
                    <table>
                        <tr>
                            <td>
                                <span class="badge badge-pill badge-primary">Feb '24</span>
                            </td>
                            <td>
                                Our paper was xxxxxx!
                            </td>
                        </tr>
                        <tr>
                            <td>
                                <span class="badge badge-pill badge-primary">Oct '23</span>
                            </td>
                            <td>
                                The pre-print is now available on <a href="https://arxiv.org/abs/xxxxx" target="_blank">arXiv</a>.
                            </td>
                        </tr>
                    </table>
                </div>

                <div class="row mt-2">
                    <div class="col-12">
                        <p>
                        </p>
                    </div>
                </div>

                <div class="row mt-2">
                    <h3>Abstract</h3>
                </div>
                <div class="row mt-2">
                    <div class="col-12 collapse-container">
                        <p class="collapse" id="abstractText" aria-expanded="false">
                            Scaling laws guide the development of large language models (LLMs) by offering estimates for the optimal balance of model size, tokens, and compute. More recently, loss-to-loss scaling laws that relate losses across pretraining datasets and downstream tasks have emerged as a powerful tool for understanding and improving LLM performance. In this work, we investigate which factors most strongly influence loss-to-loss scaling. Our experiments reveal that the pretraining data and tokenizer determine the scaling trend. In contrast, model size, optimization hyperparameters, and even significant architectural differences, such as between transformer-based models like Llama and state-space models like Mamba, have limited impact. Consequently, practitioners should carefully curate suitable pretraining datasets for optimal downstream performance, while architectures and other settings can be freely optimized for training efficiency.
                        </p>
                       <a role="button" id="moreless" class="collapsed" data-toggle="collapse" href="#abstractText" aria-expanded="false" aria-controls="abstractText"></a>
                    </div>
                </div>

                <div class="row mt-2">
                    <h3>Overview</h3>
                </div>
                <div class="row mt-2 row-dense">
                    <div class="col-12">
                        <p>
                            Object-centric representations encode each object in a sence in a separate slot.
                            Because of this, they are thought to generalize compositionlly, which means an object-centric model should be able to extract the correct representation for unseen combinations of observed objects.
                            However, in practice, when we train an object-centric autoencoder on a training set that only contains some object combinations, we find that the model performs well for seen combinations, but not for unseen ones.
                        </p>
                        <p>   
                            We pose compositional generalization as a slot identifiability problem: Is the model able to reconstruct the ground-truth slot on the training set?
                            If so, does this ability generalize to unseen combinations of objects?
                        </p>
                        <p>
                            We show that if the training set is chosen correctly, if the decoder of the model is additive, and if we train with an additional loss term that we dub <em>compositional consistency loss</em>, the model generalizes compositionally in this sense.
                        </p>
                        <div class="d-flex justify-content-center">
                            <img src="img/fig1_v12.svg" class="img-fluid" style="max-width: 100%;"/>
                        </div>
                        <small class="text-muted">
                            <p>
                                We understand compositional generalization in object-centric learning as the ability of a model to represent the objects in a scene in distinct slots, even for unseen object combinations.
                                By plotting the reconstruction error over the entire domain, we see that an additive decoder by itself generates valid images within and outside of the training set, that is, it generalizes (A).
                                But put together with the encoder, the reconstruction error shoots up outside of the training domain—the model is unable to generalize (B).
                                Only if we add our proposed <em>compositional consistency</em> objective that aligns the encoder with the decoder is the entire mdoel able to generalize (C).
                            </p>
                        </small>
                    </div>
                </div>

                <div class="row mt-2">
                    <h3>What did we essentially do and how?</h3>
                </div>
                <div class="row mt-2 row-dense">
                    <div class="col-12">
                        <p>
                            We start from a result from <a href="https://brendel-group.github.io/objects-identifiability/" data-toggle="tooltip" title data-original-title="Brady et al. 2023. Provably Learning Object-Centric Representations.">our earlier work</a> that shows that a model can correctly identify the slots of a assumed ground-truth data-generating process (that is, it can learn object-centric representations) if the model data-generation process is <em>compositional</em> and <em>irreducible</em> (both temrs introduced in our earlier work) and the model is trained on the entire domain.
                            From there, we take four steps to arrive at our final result:
                        </p>
                        <div class="d-flex justify-content-center">
                            <img src="img/fig2_v10.svg" class="img-fluid" style="max-width: 100%;"/>
                        </div>
                        <ol>
                            <li>We assume all the training data is generated from a <em>slot-supported subset</em> of the data domain, which is any subset that contains all variations of each individual object, but not necessarily all combinations of all objects.</li>
                            <li>We extend our earlier result to show that a <em>compositional</em> autoencoder trained via a reconstruction objective can still identify the ground-truth slots on this training domain if the slot-supported subset is also convex. Note that the recovered training subset of the latent space (blue) is not exactly the same as the ground-truth, since the model recovers it only up to some permissible ambiguities.</li>
                            <li>Since the model recovered the individual slots, we can simply recombine them to obtain unseen combinations of objects in the model's latent space. We show that if the decoder is additive, its reconstructions of these unseen combinations correspond exactly to images of unseen object combinations.</li>
                            <li>However, for unseen object combinations, the encoder initially does not produce representations that can be expressed by a recombination of slots in the models latent space. We therefore need to align the encoder output with the expected input to the decoder. We achieve this via our proposed <em>compositional consistency loss</em>.</li>
                        </ol>
                        <p>
                            We arrive at a model whose representations slot-identify the ground-truth latent space, even for unseen combinations of objects.
                        </p>
                    </div>
                </div>


                <div class="row mt-2">
                    <h3>What does this look like in practice?</h3>
                </div>
                <div class="row mt-2 row-dense">
                    <div class="col-12">
                        <p>
                            From an implementation perspective, our biggest contribution is the compositional consistency loss that is included as an additional training objective to the default reconstruction loss.
                            We can implement by taking the model's latent representation of the batch during the forward pass, randomly recombining slots between samples, and then applying the decoder and encoder to it. The resulting latent representation of each sample should be consistent with the recombination of latents, which we can measure, e.g., via a L2-loss.
                        </p>
                        <p>
                            In latent space, recombining the slots of two random samples will most likely lead to a combination of slots that is not part of the training domain. The decoder can produce a valid image of this slot combination since it is additive and therefore invariant to the order and combination of slots.
                        </p>
                        <div class="d-flex justify-content-center">
                            <img src="img/fig3_v6.svg" class="img-fluid" style="max-width: 100%;"/>
                        </div>
                        <small class="text-muted">
                            The compositional consistency loss enforces cycle-consistency in the model's latent space after slot-wise recombinations, similar to the cycle-consistency in image space enforced by the default reconstruction loss (left).
                            Most recombinations of slots between samples in a batch correspond to object combinations outside of the training domain (right).
                        </small>
                        <p>
                            We can show that the model slot-identifies the ground truth exactly when both losses are minimized.
                            Additionally, we do not explicitly need to optimize for compositionality of the decoder, as this property is implicitly enforced during training.
                        </p>
                        <div class="d-flex justify-content-center">
                            <img src="img/fig4_v5.svg" class="img-fluid" style="max-width: 100%;"/>
                        </div>
                        <small class="text-muted">
                             We train multiple models in a controlled setting and see that models slot-identify if they minimize both training objectives (left) and that  compositionality is implicitly satisfied (right).
                        </small>
                    </div>
                </div>


                <div class="row mt-2">
                    <h3>What does this imply?</h3>
                </div>
                <div class="row mt-2 row-dense">
                    <div class="col-12">
                        <p>
                            The popular object-centric method <a href="https://arxiv.org/abs/2006.15055" target="_blank" data-toggle="tooltip" title data-original-title="Locatello et al. 2020. Object-Centric Learning with Slot Attention">Slot Attention</a> fails to generalize compositionally <out-of-the-box class=""></out-of-the-box>
                            Given our theoretical insights, we can understand what's going wrong.
                        </p>
                        <p>
                            First, its decoder is not additive since it uses a softmax operation across slots.
                            Therefore, the decoder does not generalize.
                            Replacing the softmax with a slot-wise sigmoid fixes this issue.
                        </p>
                        <p>
                            Second, as with a vanilla autoencoder, we need to add our compositional consistency training objective to enable the whole model to generalize.
                        </p>
                        <div class="d-flex justify-content-center">
                            <img src="img/fig5_v11.svg" class="img-fluid" style="max-width: 100%;"/>
                        </div>
                        <small class="text-muted">
                            Slot Attention fails to generalize compositionally out-of-the-box, but modifying it to satisfy additivity and training with the compositional consistency loss alleviates this.
                        </small>
                    </div>
                </div>

                <div class="row">
                    <h3>Acknowledgements & Funding</h3>
                </div>
                <div class="row mt-2">
                    <div class="col-12 collapse-container">
                        <p class="collapse" id="acknowledgmentsText" aria-expanded="false">
                            We thank (in alphabetical order): xxxxxx
                            The authors thank the <a href="https://imprs.is.mpg.de/" target="_blank">International Max Planck Research School for Intelligent Systems (IMPRS-IS)</a> for supporting TW and AJ.
                        </p>
                       <a role="button" id="moreless" class="collapsed" data-toggle="collapse" href="#acknowledgmentsText" aria-expanded="false" aria-controls="acknowledgmentsText"></a>
                    </div>
                </div>
                <div class="row">
                    <h3>BibTeX</h3>
                </div>
                <div class="row">
                    <p>If you find our study helpful, please cite our paper:</p>
                </div>
                <div class="row justify-content-md-center">
                    <div class="col-sm-12 rounded p-3 m-2" style="background-color:lightgray;">
                        <small class="code">
                            @inproceedings{wiedemer2024provable,<br>
                                &nbsp;&nbsp;title={Provable Compositional Generalization for Object-Centric Learning},<br>
                                &nbsp;&nbsp;author={<br>
                                &nbsp;&nbsp;&nbsp;&nbsp;Thadd{\"a}us Wiedemer and Jack Brady and Alexander Panfilov and Attila Juhos and Matthias Bethge and Wieland Brendel<br>
                                &nbsp;&nbsp;},<br>
                                &nbsp;&nbsp;booktitle={The Twelfth International Conference on Learning Representations},<br>
                                &nbsp;&nbsp;year={2024},<br>
                                &nbsp;&nbsp;url={https://openreview.net/forum?id=7VPTUWkiDQ}<br>
                            }
                        </small>
                    </div>
                </div>

                <div class="row">
                    <small class="text-muted">Webpage designed using Bootstrap 4.5 following a layout by <a href="https://rzimmermann.com/" target="_blank">Roland Zimmermann</a>.</small>
                    <a href="#" class="ml-auto"><i class="fas fa-sort-up"></i></a>
                </div>

            </div>
        </div>

    </div>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

    <script>
        $(function () {
            $('[data-toggle="tooltip"]').tooltip()
        })
    </script>

</body>

</html>

</html>
